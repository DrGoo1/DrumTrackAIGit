<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DrumTracKAI Professional WebDAW</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: #ecf0f1;
            height: 100vh;
            overflow: hidden;
        }
        
        .webdaw-container {
            display: flex;
            flex-direction: column;
            height: 100vh;
        }
        
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 15px 20px;
            background: rgba(44, 62, 80, 0.95);
            border-bottom: 2px solid #34495e;
        }
        
        .header h1 {
            color: #3498db;
            font-size: 1.4rem;
        }
        
        .header-controls {
            display: flex;
            gap: 10px;
        }
        
        .btn {
            padding: 8px 16px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        
        .btn-primary {
            background: linear-gradient(135deg, #3498db, #2980b9);
            color: white;
        }
        
        .btn-secondary {
            background: rgba(52, 73, 94, 0.8);
            color: #ecf0f1;
            border: 1px solid #34495e;
        }
        
        .main-content {
            display: flex;
            flex: 1;
            overflow: hidden;
        }
        
        .track-area {
            flex: 1;
            display: flex;
            flex-direction: column;
            padding: 20px;
            gap: 20px;
        }
        
        .transport-controls {
            display: flex;
            align-items: center;
            gap: 20px;
            background: rgba(44, 62, 80, 0.7);
            padding: 15px;
            border-radius: 12px;
        }
        
        .transport-btn {
            width: 48px;
            height: 48px;
            border: none;
            border-radius: 50%;
            background: linear-gradient(135deg, #34495e, #2c3e50);
            color: #ecf0f1;
            font-size: 1.2rem;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .transport-btn:hover {
            background: linear-gradient(135deg, #3498db, #2980b9);
            transform: scale(1.05);
        }
        
        .transport-btn.playing {
            background: linear-gradient(135deg, #27ae60, #229954);
        }
        
        .timeline-container {
            flex: 1;
            margin: 0 20px;
        }
        
        .timeline-canvas {
            width: 100%;
            height: 60px;
            border: 2px solid #34495e;
            border-radius: 8px;
            cursor: pointer;
            background: rgba(52, 73, 94, 0.3);
        }
        
        .waveform-area {
            flex: 1;
            background: rgba(44, 62, 80, 0.7);
            border-radius: 12px;
            padding: 20px;
            overflow-y: auto;
        }
        
        .track-item {
            display: flex;
            align-items: center;
            padding: 15px;
            margin-bottom: 10px;
            background: rgba(52, 73, 94, 0.6);
            border-radius: 8px;
            gap: 15px;
        }
        
        .track-waveform {
            flex: 1;
            height: 60px;
            background: rgba(52, 73, 94, 0.8);
            border-radius: 4px;
            position: relative;
            overflow: hidden;
        }
        
        .waveform-canvas {
            width: 100%;
            height: 100%;
        }
        
        .track-controls {
            display: flex;
            flex-direction: column;
            gap: 5px;
            min-width: 60px;
        }
        
        .track-btn {
            padding: 4px 8px;
            font-size: 0.8rem;
            min-width: 24px;
            background: rgba(52, 73, 94, 0.8);
            color: #ecf0f1;
            border: 1px solid #34495e;
            border-radius: 4px;
            cursor: pointer;
        }
        
        .track-btn.active {
            background: #e74c3c;
            color: white;
        }
        
        .mixer-panel {
            width: 320px;
            background: rgba(44, 62, 80, 0.95);
            border-left: 2px solid #34495e;
            padding: 20px;
            overflow-y: auto;
        }
        
        .mixer-channel {
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 15px;
            margin-bottom: 15px;
            background: rgba(52, 73, 94, 0.6);
            border-radius: 8px;
            gap: 10px;
        }
        
        .channel-name {
            font-size: 0.9rem;
            font-weight: 500;
            text-align: center;
        }
        
        .level-meter {
            width: 20px;
            height: 100px;
            background: rgba(52, 73, 94, 0.5);
            border-radius: 10px;
            position: relative;
            overflow: hidden;
        }
        
        .level-bar {
            position: absolute;
            bottom: 0;
            width: 100%;
            border-radius: 10px;
            transition: height 0.1s ease;
            background: linear-gradient(to top, #27ae60, #f1c40f, #e67e22, #e74c3c);
        }
        
        .volume-fader {
            writing-mode: bt-lr;
            -webkit-appearance: slider-vertical;
            appearance: slider-vertical;
            width: 30px;
            height: 120px;
            background: linear-gradient(to top, #34495e, #2c3e50);
            outline: none;
            cursor: pointer;
        }
        
        .status-bar {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 20px;
            background: rgba(44, 62, 80, 0.9);
            border-top: 1px solid #34495e;
            font-size: 0.9rem;
        }
        
        .loading {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.8);
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 1000;
        }
        
        .spinner {
            width: 50px;
            height: 50px;
            border: 4px solid rgba(52, 152, 219, 0.3);
            border-top: 4px solid #3498db;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="webdaw-container">
        <!-- Header -->
        <div class="header">
            <h1>Professional WebDAW</h1>
            <div class="header-controls">
                <button class="btn btn-secondary" onclick="exportAudio()">Export</button>
                <button class="btn btn-primary" onclick="goBack()">Back</button>
            </div>
        </div>
        
        <!-- Main Content -->
        <div class="main-content">
            <!-- Track Area -->
            <div class="track-area">
                <!-- Transport Controls -->
                <div class="transport-controls">
                    <button class="transport-btn" id="playBtn" onclick="togglePlay()">‚ñ∂</button>
                    <button class="transport-btn" onclick="stop()">‚èπ</button>
                    <button class="transport-btn" onclick="toggleRecord()">‚è∫</button>
                    
                    <div class="timeline-container">
                        <canvas class="timeline-canvas" id="timelineCanvas" width="800" height="60"></canvas>
                        <div style="text-align: center; margin-top: 5px; font-size: 0.9rem;">
                            <span id="currentTime">00:00</span> / <span id="totalTime">00:00</span>
                        </div>
                    </div>
                    
                    <div style="display: flex; align-items: center; gap: 8px;">
                        <label>Tempo:</label>
                        <input type="number" id="tempoInput" value="120" min="60" max="200" 
                               style="width: 60px; padding: 4px; background: #2c3e50; color: white; border: 1px solid #34495e; border-radius: 4px;">
                        <span>BPM</span>
                    </div>
                </div>
                
                <!-- Waveform Area -->
                <div class="waveform-area">
                    <h3 style="margin-bottom: 15px; color: #3498db;">Tracks</h3>
                    <div id="trackContainer">
                        <div style="text-align: center; padding: 40px; color: #95a5a6;">
                            <p>No tracks loaded</p>
                            <p>Upload audio files or load stems to begin</p>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Mixer Panel -->
            <div class="mixer-panel">
                <h3 style="margin-bottom: 20px; color: #3498db;">Mixer</h3>
                <div id="mixerContainer">
                    <div style="text-align: center; padding: 20px; color: #95a5a6;">
                        <p>No channels</p>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Status Bar -->
        <div class="status-bar">
            <div>Status: <span id="statusText">Ready</span></div>
            <div>CPU: <span id="cpuUsage">0</span>%</div>
            <div>Tracks: <span id="trackCount">0</span></div>
        </div>
    </div>
    
    <!-- Loading Overlay -->
    <div class="loading" id="loadingOverlay" style="display: none;">
        <div>
            <div class="spinner"></div>
            <div style="margin-top: 20px; text-align: center;">Loading...</div>
        </div>
    </div>

    <script>
        class FunctionalWebDAW {
            constructor() {
                this.audioContext = null;
                this.tracks = new Map();
                this.isPlaying = false;
                this.currentTime = 0;
                this.duration = 0;
                this.tempo = 120;
                this.masterGain = null;
                this.analyser = null;
                this.animationFrame = null;
                this.websocket = null;
                
                this.init();
            }
            
            async init() {
                try {
                    // Initialize Web Audio API
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.masterGain = this.audioContext.createGain();
                    this.analyser = this.audioContext.createAnalyser();
                    
                    this.masterGain.connect(this.analyser);
                    this.analyser.connect(this.audioContext.destination);
                    
                    // Setup WebSocket connection
                    this.setupWebSocket();
                    
                    // Setup canvas
                    this.setupCanvas();
                    
                    // Check for initial data
                    this.checkForInitialData();
                    
                    console.log('‚úÖ WebDAW initialized with Web Audio API');
                } catch (error) {
                    console.error('‚ùå Failed to initialize WebDAW:', error);
                }
            }
            
            setupWebSocket() {
                try {
                    this.websocket = new WebSocket('ws://localhost:8000/ws/webdaw');
                    
                    this.websocket.onopen = () => {
                        console.log('üîå WebSocket connected');
                        this.updateStatus('Connected');
                    };
                    
                    this.websocket.onmessage = (event) => {
                        const data = JSON.parse(event.data);
                        this.handleWebSocketMessage(data);
                    };
                    
                    this.websocket.onerror = (error) => {
                        console.error('‚ùå WebSocket error:', error);
                        this.updateStatus('Connection Error');
                    };
                    
                    this.websocket.onclose = () => {
                        console.log('üîå WebSocket disconnected');
                        this.updateStatus('Disconnected');
                        // Attempt reconnection
                        setTimeout(() => this.setupWebSocket(), 5000);
                    };
                } catch (error) {
                    console.error('‚ùå WebSocket setup failed:', error);
                }
            }
            
            handleWebSocketMessage(data) {
                switch (data.type) {
                    case 'load_stems':
                        // Automatic stem loading from analysis
                        this.loadStemsFromAnalysis(data);
                        break;
                    case 'stem_data':
                        this.loadStemData(data.stems);
                        break;
                    case 'analysis_data':
                        this.loadAnalysisData(data.analysis);
                        break;
                    case 'level_update':
                        this.updateLevelMeters(data.levels);
                        break;
                    default:
                        console.log('üì® Unknown message:', data);
                }
            }
            
            async loadStemsFromAnalysis(data) {
                console.log('üéµ Auto-loading stems from analysis:', data);
                
                try {
                    const stems = data.stems || {};
                    const analysis = data.analysis || {};
                    
                    // Show notification
                    this.showNotification(`üéµ Auto-loading ${Object.keys(stems).length} stems from analysis...`);
                    
                    // Load stems
                    await this.loadStemData(stems);
                    
                    // Update tempo from analysis
                    if (analysis.tempo) {
                        this.updateTempo(analysis.tempo);
                    }
                    
                    // Show success notification
                    this.showNotification(`‚úÖ Successfully loaded ${Object.keys(stems).length} stems automatically!`);
                    
                } catch (error) {
                    console.error('‚ùå Failed to auto-load stems:', error);
                    this.showNotification('‚ùå Failed to load stems from analysis');
                }
            }
            
            async loadStemData(stemData) {
                this.showLoading(true);
                
                try {
                    const trackContainer = document.getElementById('trackContainer');
                    const mixerContainer = document.getElementById('mixerContainer');
                    
                    // Don't clear existing tracks - add to them
                    // trackContainer.innerHTML = '';
                    // mixerContainer.innerHTML = '';
                    // this.tracks.clear();
                    
                    for (const [stemType, stemInfo] of Object.entries(stemData)) {
                        // Skip if track already exists
                        if (this.tracks.has(stemType)) {
                            console.log(`‚è≠Ô∏è Stem ${stemType} already exists, skipping`);
                            continue;
                        }
                        
                        await this.createStemTrack(stemType, stemInfo);
                    }
                    
                    this.updateTrackCount();
                    this.updateStatus('Stems Loaded');
                    console.log(`‚úÖ Loaded ${this.tracks.size} total tracks`);
                    
                } catch (error) {
                    console.error('‚ùå Failed to load stems:', error);
                    this.updateStatus('Load Error');
                } finally {
                    this.showLoading(false);
                }
            }
            
            async createStemTrack(stemType, stemInfo) {
                try {
                    let audioBuffer;
                    
                    if (stemInfo.url && stemInfo.url.startsWith('/demo/')) {
                        // Mock data - create audio buffer from waveform
                        audioBuffer = this.createMockAudioBuffer(stemInfo);
                    } else if (stemInfo.url) {
                        // Real audio file
                        const audioResponse = await fetch(`http://localhost:8000${stemInfo.url}`);
                        const audioArrayBuffer = await audioResponse.arrayBuffer();
                        audioBuffer = await this.audioContext.decodeAudioData(audioArrayBuffer);
                    } else {
                        // No audio data - create silent buffer
                        audioBuffer = this.audioContext.createBuffer(2, 44100 * 2, 44100);
                    }
                    
                    // Create track object
                    const track = {
                        id: stemType,
                        name: stemInfo.name || stemType.charAt(0).toUpperCase() + stemType.slice(1),
                        type: stemType,
                        buffer: audioBuffer,
                        source: null,
                        gainNode: this.audioContext.createGain(),
                        panNode: this.audioContext.createStereoPanner(),
                        analyser: this.audioContext.createAnalyser(),
                        muted: false,
                        soloed: false,
                        volume: 0.8,
                        pan: 0,
                        color: this.getTrackColor(stemType)
                    };
                    
                    // Connect audio nodes
                    track.gainNode.connect(track.panNode);
                    track.panNode.connect(track.analyser);
                    track.analyser.connect(this.masterGain);
                    
                    // Set initial values
                    track.gainNode.gain.value = track.volume;
                    track.panNode.pan.value = track.pan;
                    
                    this.tracks.set(track.id, track);
                    
                    // Create UI elements
                    this.createTrackUI(track);
                    this.createMixerChannel(track);
                    
                    // Update duration
                    this.duration = Math.max(this.duration, audioBuffer.duration);
                    this.updateTimeDisplay();
                    
                    console.log(`üéµ Stem track created: ${track.name}`);
                    
                } catch (error) {
                    console.error(`‚ùå Failed to create stem track for ${stemType}:`, error);
                }
            }
            
            createMockAudioBuffer(stemInfo) {
                const duration = stemInfo.duration || 120;
                const sampleRate = stemInfo.sample_rate || 44100;
                const samples = Math.floor(duration * sampleRate);
                const audioBuffer = this.audioContext.createBuffer(2, samples, sampleRate);
                
                // Fill with waveform data if available
                if (stemInfo.waveform && stemInfo.waveform.length > 0) {
                    const leftChannel = audioBuffer.getChannelData(0);
                    const rightChannel = audioBuffer.getChannelData(1);
                    
                    for (let i = 0; i < samples; i++) {
                        const waveformIndex = Math.floor((i / samples) * stemInfo.waveform.length);
                        const value = stemInfo.waveform[waveformIndex] || 0;
                        leftChannel[i] = value * 0.1; // Reduce volume for mock data
                        rightChannel[i] = value * 0.1;
                    }
                }
                
                return audioBuffer;
            }
            
            async createTrack(stemType, audioData) {
                try {
                    // Convert audio data to AudioBuffer
                    const audioBuffer = await this.audioContext.decodeAudioData(audioData);
                    
                    // Create track object
                    const track = {
                        id: `track_${this.tracks.size}`,
                        name: stemType.charAt(0).toUpperCase() + stemType.slice(1),
                        type: stemType,
                        buffer: audioBuffer,
                        source: null,
                        gainNode: this.audioContext.createGain(),
                        panNode: this.audioContext.createStereoPanner(),
                        analyser: this.audioContext.createAnalyser(),
                        muted: false,
                        soloed: false,
                        volume: 0.8,
                        pan: 0,
                        color: this.getTrackColor(stemType)
                    };
                    
                    // Connect audio nodes
                    track.gainNode.connect(track.panNode);
                    track.panNode.connect(track.analyser);
                    track.analyser.connect(this.masterGain);
                    
                    // Set initial values
                    track.gainNode.gain.value = track.volume;
                    track.panNode.pan.value = track.pan;
                    
                    this.tracks.set(track.id, track);
                    
                    // Create UI elements
                    this.createTrackUI(track);
                    this.createMixerChannel(track);
                    
                    // Update duration
                    this.duration = Math.max(this.duration, audioBuffer.duration);
                    this.updateTimeDisplay();
                    
                } catch (error) {
                    console.error(`‚ùå Failed to create track for ${stemType}:`, error);
                }
            }
            
            createTrackUI(track) {
                const trackContainer = document.getElementById('trackContainer');
                
                const trackElement = document.createElement('div');
                trackElement.className = 'track-item';
                trackElement.innerHTML = `
                    <div style="min-width: 100px;">
                        <div class="channel-name" style="color: ${track.color}">${track.name}</div>
                        <div style="font-size: 0.8rem; color: #95a5a6;">${track.type}</div>
                    </div>
                    <div class="track-waveform">
                        <canvas class="waveform-canvas" id="waveform_${track.id}" width="600" height="60"></canvas>
                    </div>
                    <div class="track-controls">
                        <button class="track-btn" onclick="webDAW.toggleMute('${track.id}')">M</button>
                        <button class="track-btn" onclick="webDAW.toggleSolo('${track.id}')">S</button>
                    </div>
                `;
                
                trackContainer.appendChild(trackElement);
                
                // Draw waveform
                this.drawWaveform(track);
            }
            
            createMixerChannel(track) {
                const mixerContainer = document.getElementById('mixerContainer');
                
                const channelElement = document.createElement('div');
                channelElement.className = 'mixer-channel';
                channelElement.innerHTML = `
                    <div class="channel-name" style="color: ${track.color}">${track.name}</div>
                    
                    <div class="level-meter">
                        <div class="level-bar" id="level_${track.id}" style="height: 0%"></div>
                    </div>
                    
                    <input type="range" class="volume-fader" 
                           min="0" max="1" step="0.01" value="${track.volume}"
                           onchange="webDAW.setVolume('${track.id}', this.value)"
                           orient="vertical">
                    
                    <div style="font-size: 0.8rem; color: #95a5a6;">
                        Vol: <span id="vol_${track.id}">${Math.round(track.volume * 100)}</span>%
                    </div>
                    
                    <input type="range" min="-1" max="1" step="0.01" value="${track.pan}"
                           onchange="webDAW.setPan('${track.id}', this.value)"
                           style="width: 60px;">
                    
                    <div style="font-size: 0.8rem; color: #95a5a6;">Pan</div>
                `;
                
                mixerContainer.appendChild(channelElement);
            }
            
            drawWaveform(track) {
                const canvas = document.getElementById(`waveform_${track.id}`);
                if (!canvas) return;
                
                const ctx = canvas.getContext('2d');
                const width = canvas.width;
                const height = canvas.height;
                
                // Clear canvas
                ctx.fillStyle = '#2c3e50';
                ctx.fillRect(0, 0, width, height);
                
                // Draw waveform from audio buffer
                const buffer = track.buffer;
                const data = buffer.getChannelData(0); // Use first channel
                const step = Math.ceil(data.length / width);
                const amp = height / 2;
                
                ctx.strokeStyle = track.color;
                ctx.lineWidth = 1;
                ctx.beginPath();
                
                for (let i = 0; i < width; i++) {
                    let min = 1.0;
                    let max = -1.0;
                    
                    for (let j = 0; j < step; j++) {
                        const datum = data[(i * step) + j];
                        if (datum < min) min = datum;
                        if (datum > max) max = datum;
                    }
                    
                    ctx.moveTo(i, (1 + min) * amp);
                    ctx.lineTo(i, (1 + max) * amp);
                }
                
                ctx.stroke();
            }
            
            getTrackColor(stemType) {
                const colors = {
                    vocals: '#ff6b6b',
                    drums: '#4ecdc4',
                    bass: '#45b7d1',
                    other: '#96ceb4',
                    piano: '#feca57',
                    guitar: '#ff9ff3'
                };
                return colors[stemType] || '#95a5a6';
            }
            
            async togglePlay() {
                if (this.audioContext.state === 'suspended') {
                    await this.audioContext.resume();
                }
                
                if (this.isPlaying) {
                    this.pause();
                } else {
                    this.play();
                }
            }
            
            play() {
                this.isPlaying = true;
                const playBtn = document.getElementById('playBtn');
                playBtn.textContent = '‚è∏';
                playBtn.classList.add('playing');
                
                // Start all tracks
                this.tracks.forEach(track => {
                    if (!track.muted && track.buffer) {
                        track.source = this.audioContext.createBufferSource();
                        track.source.buffer = track.buffer;
                        track.source.connect(track.gainNode);
                        track.source.start(0, this.currentTime);
                    }
                });
                
                this.updateStatus('Playing');
                this.startTimeUpdate();
            }
            
            pause() {
                this.isPlaying = false;
                const playBtn = document.getElementById('playBtn');
                playBtn.textContent = '‚ñ∂';
                playBtn.classList.remove('playing');
                
                // Stop all tracks
                this.tracks.forEach(track => {
                    if (track.source) {
                        track.source.stop();
                        track.source = null;
                    }
                });
                
                this.updateStatus('Paused');
                if (this.animationFrame) {
                    cancelAnimationFrame(this.animationFrame);
                }
            }
            
            stop() {
                this.pause();
                this.currentTime = 0;
                this.updateTimeDisplay();
                this.updateStatus('Stopped');
            }
            
            updateTempo(tempo) {
                this.tempo = tempo;
                const tempoDisplay = document.querySelector('.tempo-display');
                if (tempoDisplay) {
                    tempoDisplay.textContent = `${tempo} BPM`;
                }
                console.log(`üéµ Tempo updated to ${tempo} BPM`);
            }
            
            showNotification(message, type = 'info') {
                console.log(`üîî ${message}`);
                
                // Create notification element
                const notification = document.createElement('div');
                notification.className = `notification notification-${type}`;
                notification.textContent = message;
                notification.style.cssText = `
                    position: fixed;
                    top: 20px;
                    right: 20px;
                    background: ${type === 'error' ? '#e74c3c' : type === 'success' ? '#27ae60' : '#3498db'};
                    color: white;
                    padding: 12px 20px;
                    border-radius: 6px;
                    z-index: 10000;
                    font-weight: 500;
                    box-shadow: 0 4px 12px rgba(0,0,0,0.3);
                    animation: slideIn 0.3s ease;
                `;
                
                document.body.appendChild(notification);
                
                // Auto-remove after 4 seconds
                setTimeout(() => {
                    if (notification.parentNode) {
                        notification.style.animation = 'slideOut 0.3s ease';
                        setTimeout(() => notification.remove(), 300);
                    }
                }, 4000);
            }
            
            setupMidiUpload() {
                // Add MIDI upload button to header
                const headerControls = document.querySelector('.header-controls');
                if (headerControls) {
                    const midiUploadBtn = document.createElement('button');
                    midiUploadBtn.className = 'btn btn-secondary';
                    midiUploadBtn.innerHTML = 'üéπ Upload MIDI';
                    midiUploadBtn.onclick = () => this.openMidiUpload();
                    headerControls.appendChild(midiUploadBtn);
                }
                
                // Create hidden file input for MIDI
                const midiInput = document.createElement('input');
                midiInput.type = 'file';
                midiInput.accept = '.mid,.midi';
                midiInput.style.display = 'none';
                midiInput.onchange = (e) => this.handleMidiUpload(e.target.files[0]);
                document.body.appendChild(midiInput);
                this.midiInput = midiInput;
            }
            
            openMidiUpload() {
                this.midiInput.click();
            }
            
            async handleMidiUpload(file) {
                if (!file) return;
                
                this.showLoading(true);
                this.updateStatus('Uploading MIDI...');
                
                try {
                    const formData = new FormData();
                    formData.append('file', file);
                    
                    const response = await fetch('http://localhost:8000/api/upload/midi', {
                        method: 'POST',
                        body: formData
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        console.log('üéπ MIDI uploaded successfully:', result);
                        
                        // Create audio track from MIDI
                        if (result.audio_data && result.audio_data.success) {
                            await this.createMidiTrack(result.audio_data, file.name);
                        }
                        
                        this.showNotification(`üéπ MIDI file "${file.name}" uploaded and converted!`);
                        this.updateStatus('MIDI Loaded');
                    } else {
                        throw new Error(result.message || 'MIDI upload failed');
                    }
                } catch (error) {
                    console.error('‚ùå MIDI upload error:', error);
                    this.showNotification(`‚ùå Failed to upload MIDI: ${error.message}`);
                    this.updateStatus('Upload Error');
                } finally {
                    this.showLoading(false);
                }
            }
            
            async createMidiTrack(audioData, filename) {
                try {
                    // Fetch the converted audio file
                    const audioResponse = await fetch(`http://localhost:8000${audioData.url}`);
                    const audioArrayBuffer = await audioResponse.arrayBuffer();
                    const audioBuffer = await this.audioContext.decodeAudioData(audioArrayBuffer);
                    
                    // Create track object
                    const track = {
                        id: `midi_${Date.now()}`,
                        name: filename.replace(/\.(mid|midi)$/i, ''),
                        type: 'midi',
                        buffer: audioBuffer,
                        source: null,
                        gainNode: this.audioContext.createGain(),
                        panNode: this.audioContext.createStereoPanner(),
                        analyser: this.audioContext.createAnalyser(),
                        muted: false,
                        soloed: false,
                        volume: 0.8,
                        pan: 0,
                        color: '#9b59b6' // Purple for MIDI tracks
                    };
                    
                    // Connect audio nodes
                    track.gainNode.connect(track.panNode);
                    track.panNode.connect(track.analyser);
                    track.analyser.connect(this.masterGain);
                    
                    // Set initial values
                    track.gainNode.gain.value = track.volume;
                    track.panNode.pan.value = track.pan;
                    
                    this.tracks.set(track.id, track);
                    
                    // Create UI elements
                    this.createTrackUI(track);
                    this.createMixerChannel(track);
                    
                    // Update duration
                    this.duration = Math.max(this.duration, audioBuffer.duration);
                    this.updateTimeDisplay();
                    this.updateTrackCount();
                    
                    console.log(`üéπ MIDI track created: ${track.name}`);
                } catch (error) {
                    console.error('‚ùå Failed to create MIDI track:', error);
                    this.showNotification('‚ùå Failed to create MIDI track');
                }
            }
            
            setVolume(trackId, value) {
                const track = this.tracks.get(trackId);
                if (track) {
                    track.volume = parseFloat(value);
                    track.gainNode.gain.value = track.volume;
                    document.getElementById(`vol_${trackId}`).textContent = Math.round(track.volume * 100);
                }
            }
            
            setPan(trackId, value) {
                const track = this.tracks.get(trackId);
                if (track) {
                    track.pan = parseFloat(value);
                    track.panNode.pan.value = track.pan;
                }
            }
            
            toggleMute(trackId) {
                const track = this.tracks.get(trackId);
                if (track) {
                    track.muted = !track.muted;
                    track.gainNode.gain.value = track.muted ? 0 : track.volume;
                }
            }
            
            toggleSolo(trackId) {
                const track = this.tracks.get(trackId);
                if (track) {
                    track.soloed = !track.soloed;
                    // Implement solo logic
                }
            }
            
            startTimeUpdate() {
                const startTime = this.audioContext.currentTime - this.currentTime;
                
                const update = () => {
                    if (!this.isPlaying) return;
                    
                    this.currentTime = this.audioContext.currentTime - startTime;
                    
                    if (this.currentTime >= this.duration) {
                        this.stop();
                        return;
                    }
                    
                    this.updateTimeDisplay();
                    this.updateLevelMeters();
                    this.animationFrame = requestAnimationFrame(update);
                };
                
                update();
            }
            
            updateTimeDisplay() {
                document.getElementById('currentTime').textContent = this.formatTime(this.currentTime);
                document.getElementById('totalTime').textContent = this.formatTime(this.duration);
            }
            
            formatTime(seconds) {
                const mins = Math.floor(seconds / 60);
                const secs = Math.floor(seconds % 60);
                return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
            }
            
            updateLevelMeters() {
                this.tracks.forEach(track => {
                    if (track.analyser && this.isPlaying && !track.muted) {
                        const dataArray = new Uint8Array(track.analyser.frequencyBinCount);
                        track.analyser.getByteFrequencyData(dataArray);
                        
                        const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                        const level = (average / 255) * 100;
                        
                        const levelBar = document.getElementById(`level_${track.id}`);
                        if (levelBar) {
                            levelBar.style.height = `${level}%`;
                        }
                    }
                });
            }
            
            updateStatus(status) {
                document.getElementById('statusText').textContent = status;
            }
            
            updateTrackCount() {
                document.getElementById('trackCount').textContent = this.tracks.size;
            }
            
            showLoading(show) {
                document.getElementById('loadingOverlay').style.display = show ? 'flex' : 'none';
            }
            
            checkForInitialData() {
                // Check if parent window has data to load
                if (window.parent && window.parent !== window) {
                    window.parent.postMessage({ type: 'webdaw_ready' }, '*');
                }
            }
            
            setupCanvas() {
                const canvas = document.getElementById('timelineCanvas');
                const ctx = canvas.getContext('2d');
                
                canvas.addEventListener('click', (e) => {
                    const rect = canvas.getBoundingClientRect();
                    const x = e.clientX - rect.left;
                    const position = (x / canvas.width) * this.duration;
                    this.seek(position);
                });
            }
            
            seek(position) {
                this.currentTime = Math.max(0, Math.min(position, this.duration));
                if (this.isPlaying) {
                    this.pause();
                    this.play();
                }
                this.updateTimeDisplay();
            }
        }
        
        // Global functions
        let webDAW;
        
        window.addEventListener('load', () => {
            webDAW = new FunctionalWebDAW();
        });
        
        function togglePlay() {
            webDAW.togglePlay();
        }
        
        function stop() {
            webDAW.stop();
        }
        
        function toggleRecord() {
            console.log('üî¥ Record functionality not implemented yet');
        }
        
        function exportAudio() {
            console.log('üìÅ Export functionality not implemented yet');
        }
        
        function goBack() {
            if (window.parent && window.parent !== window) {
                window.parent.postMessage({ type: 'webdaw_back' }, '*');
            }
        }
        
        // Listen for messages from parent
        window.addEventListener('message', (event) => {
            if (event.data.type === 'load_stems') {
                webDAW.loadStemData(event.data.stems);
            } else if (event.data.type === 'load_analysis') {
                webDAW.loadAnalysisData(event.data.analysis);
            }
        });
    </script>
</body>
</html>
